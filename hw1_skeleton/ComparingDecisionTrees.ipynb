{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7234b585",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "':' expected after dictionary key (1852212338.py, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 44\u001b[1;36m\u001b[0m\n\u001b[1;33m    ...\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m ':' expected after dictionary key\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def evaluatePerformance():\n",
    "    '''\n",
    "    Evaluate the performance of decision trees,\n",
    "    averaged over 100 trials of 10-fold cross-validation\n",
    "    \n",
    "    Return:\n",
    "      a matrix giving the performance that will contain the following entries:\n",
    "      stats[0,0] = mean accuracy of decision tree\n",
    "      stats[0,1] = std deviation of decision tree accuracy\n",
    "      stats[1,0] = mean accuracy of decision stump\n",
    "      stats[1,1] = std deviation of decision stump\n",
    "      stats[2,0] = mean accuracy of 3-level decision tree\n",
    "      stats[2,1] = std deviation of 3-level decision tree\n",
    "      \n",
    "    ** Note that your implementation must follow this API**\n",
    "    '''\n",
    "\n",
    "    # Load Data\n",
    "    filename = 'data/SPECTF.dat'\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "    X = data[:, 1:]\n",
    "    y = np.array([data[:, 0]]).T\n",
    "    n, d = X.shape\n",
    "\n",
    "    # Initialize variables to store results\n",
    "    decision_tree_accuracies = []\n",
    "    decision_stump_accuracies = []\n",
    "    dt3_accuracies = []\n",
    "\n",
    "    # Initialize lists to store learning curve data\n",
    "    learning_curve_data = {\n",
    "        'Decision Tree': [],\n",
    "        'Decision Stump': [],\n",
    "        '3-level Decision Tree': [],\n",
    "        'DT_depth_5': [],\n",
    "        'DT_depth_8': [],\n",
    "        ...\n",
    "    }\n",
    "\n",
    "    # Perform 100 trials of 10-fold cross-validation\n",
    "    for _ in range(100):\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # Train the decision tree\n",
    "            for tree_depth in [None, 1, 3, 5, 8]:\n",
    "                clf = tree.DecisionTreeClassifier(max_depth=tree_depth)\n",
    "                clf = clf.fit(X_train, y_train)\n",
    "\n",
    "                # Output predictions on the test set\n",
    "                y_pred = clf.predict(X_test)\n",
    "\n",
    "                # Compute accuracy of the model\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "                # Add accuracy to corresponding list\n",
    "                if tree_depth is None:\n",
    "                    decision_tree_accuracies.append(accuracy)\n",
    "                elif tree_depth == 1:\n",
    "                    decision_stump_accuracies.append(accuracy)\n",
    "                elif tree_depth == 3:\n",
    "                    dt3_accuracies.append(accuracy)\n",
    "                else:\n",
    "                    # Add accuracy to corresponding list for additional decision trees\n",
    "                    learning_curve_data[f'DT_depth_{tree_depth}'].append(accuracy)\n",
    "\n",
    "                # Calculate learning curve data for different subsets of training data\n",
    "                for subset in np.arange(0.1, 1.1, 0.1):\n",
    "                    subset_index = int(len(X_train) * subset)\n",
    "                    X_subset_train = X_train[:subset_index]\n",
    "                    y_subset_train = y_train[:subset_index]\n",
    "\n",
    "                    # Train the classifier on subset of training data\n",
    "                    clf_subset = tree.DecisionTreeClassifier(max_depth=tree_depth)\n",
    "                    clf_subset = clf_subset.fit(X_subset_train, y_subset_train)\n",
    "\n",
    "                    # Test accuracy on test set\n",
    "                    y_subset_pred = clf_subset.predict(X_test)\n",
    "                    mean_decision_tree_accuracies = np.mean(decision_tree_accuracies)\n",
    "                    std_decision_tree_accuracies = np.std(decision_tree_accuracies)\n",
    "\n",
    "                    mean_decision_stump_accuracies = np.mean(decision_stump_accuracies)\n",
    "                    std_decision_stump_accuracies = np.std(decision_stump_accuracies)\n",
    "\n",
    "                    mean_dt3_accuracies = np.mean(dt3_accuracies)\n",
    "                    std_dt3_accuracies = np.std(dt3_accuracies)\n",
    "\n",
    "                for classifier, curve_data in learning_curve_data.items():\n",
    "                    mean_curve = np.mean(np.array(curve_data).reshape(-1, 10), axis=0)\n",
    "                    std_curve = np.std(np.array(curve_data).reshape(-1, 10), axis=0)\n",
    "\n",
    "                    # Calculate mean and standard deviation of accuracies\n",
    "                    mean_accuracies = np.mean(curve_data)\n",
    "                    std_accuracies = np.std(curve_data)\n",
    "\n",
    "                    # Add mean and standard deviation to corresponding lists\n",
    "                    learning_curve_data[classifier]['mean'] = mean_accuracies\n",
    "                    learning_curve_data[classifier]['std'] = std_accuracies\n",
    "\n",
    "                # Generate learning curves plot\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                for classifier, curve_data in learning_curve_data.items():\n",
    "                    mean_curve = np.mean(np.array(curve_data).reshape(-1, 10), axis=0)\n",
    "                    std_curve = np.std(np.array(curve_data).reshape(-1, 10), axis=0)\n",
    "                    plt.errorbar(np.arange(0.1, 1.1, 0.1) * 100, mean_curve, yerr=std_curve, label=classifier)\n",
    "\n",
    "                plt.xlabel('% of Training Data')\n",
    "                plt.ylabel('Accuracy')\n",
    "                plt.title('Learning Curve for Different Classifiers')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                plt.show()\n",
    "\n",
    "                # Return statistics matrix\n",
    "                stats = np.zeros((5, 2))\n",
    "                stats[0, 0] = mean_decision_tree_accuracies\n",
    "                stats[0, 1] = std_decision_tree_accuracies\n",
    "                stats[1, 0] = mean_decision_stump_accuracies\n",
    "                stats[1, 1] = std_decision_stump_accuracies\n",
    "                stats[2, 0] = mean_dt3_accuracies\n",
    "                stats[2, 1] = std_dt3_accuracies\n",
    "                return stats\n",
    "if __name__ == \"__main__\":\n",
    "    stats = evaluatePerformance()\n",
    "    print(\"Decision Tree Accuracy = \", stats[0, 0], \" (\", stats[0, 1], \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed31b4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
